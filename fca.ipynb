{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63efd82d-3369-4eda-97f3-e4d2e9a9667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "if sys.platform == 'linux':\n",
    "    __import__('pysqlite3')\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "import chromadb\n",
    "from apify_client import ApifyClient\n",
    "from chromadb.config import Settings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import QianfanLLMEndpoint, Tongyi\n",
    "from langchain_community.utilities import (BingSearchAPIWrapper,\n",
    "                                           GoogleSearchAPIWrapper,\n",
    "                                           GoogleSerperAPIWrapper)\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8990152-3233-4878-a137-a540f472679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_urls(key_words: str,\n",
    "               search_engine_wrapper: str = 'Bing',\n",
    "               num_results: int = 10,\n",
    "               exclude_list: list[str] = [\n",
    "                   r'163\\.com',\n",
    "                   r'ys80007\\.com',\n",
    "                   r'wyzxwk\\.com',\n",
    "                   r'bijie.gov.cn',\n",
    "                   r'yongxiu.gov.cn']):\n",
    "    logging.info(f'Getting URLs from {search_engine_wrapper} search...')\n",
    "\n",
    "    if search_engine_wrapper == 'Google' and num_results > 10:\n",
    "        logging.error(\n",
    "            'GoogleSearchAPI only supports up to 10 resutls, try other engines like Bing/GoogleSerper.')\n",
    "        return\n",
    "\n",
    "    if search_engine_wrapper == 'Google':\n",
    "        search_engine = GoogleSearchAPIWrapper(k=num_results)\n",
    "    elif search_engine_wrapper == 'GoogleSerper':\n",
    "        search_engine = GoogleSerperAPIWrapper(k=num_results)\n",
    "    elif search_engine_wrapper == 'Bing':\n",
    "        search_engine = BingSearchAPIWrapper(k=num_results)\n",
    "    else:\n",
    "        logging.error(f'Search engine {search_engine_wrapper} not supported.')\n",
    "        return\n",
    "\n",
    "    search_results = search_engine.results(key_words, num_results=num_results)\n",
    "    if search_engine_wrapper == 'GoogleSerper':\n",
    "        urls = [item['link'] for item in search_results['organic']]\n",
    "    else:\n",
    "        urls = [item['link'] for item in search_results]\n",
    "\n",
    "    urls_filtered = []\n",
    "    for url in urls:\n",
    "        include_flag = True\n",
    "        for exclude_pattern in exclude_list:\n",
    "            if re.search(exclude_pattern, url):\n",
    "                include_flag = False\n",
    "                break\n",
    "        if include_flag:\n",
    "            urls_filtered.append(url)\n",
    "    return [{'url': url} for url in urls_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b654a529-582e-452a-8219-c383c4a1e03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.sas.com/en_us/home.html'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/SAS_Institute'},\n",
       " {'url': 'https://www.glassdoor.com/Overview/Working-at-SAS-EI_IE3807.11,14.htm'},\n",
       " {'url': 'https://www.techtarget.com/searchbusinessanalytics/definition/SAS-Institute-Inc'},\n",
       " {'url': 'https://www.iu5.org/sas'},\n",
       " {'url': 'https://winmo.com/open/company/technology-software/nc/cary/sas-institute-inc/7358'},\n",
       " {'url': 'https://www.greatplacetowork.com/certified-company/1000230'},\n",
       " {'url': 'https://www.linkedin.com/company/sas'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# urls_filtered = fetch_urls('SAS Institute', search_engine_wrapper='GoogleSerper', num_results=10)\n",
    "# urls_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d43140-dbc6-41a9-be23-503969bbf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_web_content(urls_filtered: list[str],\n",
    "                      crawler_type: str = 'cheerio',\n",
    "                      min_text_length: int = 50):\n",
    "    logging.info('Getting detailed web content from each URL...')\n",
    "\n",
    "    apify_client = ApifyClient(os.getenv('APIFY_API_TOKEN'))\n",
    "    actor_call = apify_client.actor('apify/website-content-crawler').call(\n",
    "        run_input={\n",
    "            'startUrls': urls_filtered,\n",
    "            'crawlerType': crawler_type,\n",
    "            'maxCrawlDepth': 0,\n",
    "            'maxSessionRotations': 0,\n",
    "            'proxyConfiguration': {'useApifyProxy': True},\n",
    "        })\n",
    "    apify_dataset = apify_client.dataset(\n",
    "        actor_call['defaultDatasetId']).list_items().items\n",
    "\n",
    "    records = [rec for rec in apify_dataset if rec['crawl']['httpStatusCode'] < 300\n",
    "               and len(rec['text']) >= min_text_length]\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9803318-37c9-48d2-a361-8d9aacce5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# records = fetch_web_content(urls_filtered)\n",
    "# records[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a49059fd-5f31-48f6-b76f-53e79f69bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization_store(records: list[dict],\n",
    "                        key_words: str,\n",
    "                        chunk_size: int = 1000,\n",
    "                        chunk_overlap: int = 100,\n",
    "                        persistent_dir = './chroma'):\n",
    "    logging.info(f'Vectorizing documents into ChromaDB...')\n",
    "\n",
    "    docs = []\n",
    "    for rec in records:\n",
    "        doc = Document(page_content=rec['text'],\n",
    "                       metadata={'source': rec['url']})\n",
    "        docs.append(doc)\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "    chunked_docs = splitter.split_documents(docs)\n",
    "\n",
    "    client = chromadb.PersistentClient(\n",
    "        path=persistent_dir,\n",
    "        settings=Settings(anonymized_telemetry=False))\n",
    "\n",
    "    collection_name = uuid.uuid3(uuid.NAMESPACE_DNS, key_words).hex\n",
    "\n",
    "    langchain_chroma = Chroma(\n",
    "        collection_name,\n",
    "        embedding_function=HuggingFaceEmbeddings(),\n",
    "        client=client\n",
    "    )\n",
    "\n",
    "    ids = langchain_chroma.add_documents(chunked_docs)\n",
    "    logging.info(\n",
    "        f'{len(ids)} documents were added into collection {collection_name}')\n",
    "\n",
    "    return collection_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f35d08-69a5-41c1-9b66-bdc101e80e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sas/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'9d4679e83e3d355ca4f44bae597a9361'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collection_name = vectorization_store(records, 'SAS Institute')\n",
    "# collection_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f476667-15a4-4271-8679-d57c5026c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_over_docs(collection_name: str,\n",
    "                 general_qa_template: str,\n",
    "                 query: str,\n",
    "                 persistent_dir = './chroma',\n",
    "                 llm_provider: str = 'Alibaba'):\n",
    "    client = chromadb.PersistentClient(\n",
    "        path=persistent_dir,\n",
    "        settings=Settings(anonymized_telemetry=False))\n",
    "\n",
    "    langchain_chroma = Chroma(\n",
    "        collection_name,\n",
    "        embedding_function=HuggingFaceEmbeddings(),\n",
    "        client=client\n",
    "    )\n",
    "\n",
    "    mmr_retriever = langchain_chroma.as_retriever(\n",
    "        search_type='mmr',\n",
    "        search_kwargs={'k': 3, 'fetch_k': 5}\n",
    "    )\n",
    "\n",
    "    logging.info(f'Documents QA using LLM provied by {llm_provider}...')\n",
    "    if llm_provider == 'Alibaba':\n",
    "        llm = Tongyi(model_name='qwen-max', temperature=0)\n",
    "    elif llm_provider == 'Baidu':\n",
    "        llm = QianfanLLMEndpoint(model='ERNIE-Bot', temperature=0.01)\n",
    "    elif llm_provider == 'OpenAI':\n",
    "        llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "    else:\n",
    "        logging.error(f'LLM provider {llm_provider} not supported.')\n",
    "        return\n",
    "\n",
    "    rag_prompt = PromptTemplate.from_template(general_qa_template)\n",
    "    rag_chain = (\n",
    "        {'context': mmr_retriever, 'question': RunnablePassthrough()}\n",
    "        | rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    try:\n",
    "        answer = rag_chain.invoke(query)\n",
    "        return {\n",
    "            'query': query,\n",
    "            'answer': answer\n",
    "        }\n",
    "    except ValueError:  # Occurs when there is no relevant information\n",
    "        return {\n",
    "            'query': query,\n",
    "            'answer': 'I don\\'t know.'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a709457-7785-43e9-8fff-3242159b2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proj settings\n",
    "# COMPANY_NAME = 'Rothenberg Ventures Management Company, LLC.'\n",
    "COMPANY_NAME = '红岭创投'\n",
    "# COMPANY_NAME = '恒大财富'\n",
    "# COMPANY_NAME = '鸿博股份'\n",
    "# COMPANY_NAME = '平安银行'\n",
    "# COMPANY_NAME = 'Theranos'\n",
    "# COMPANY_NAME = 'BridgeWater Fund'\n",
    "# COMPANY_NAME = 'SAS Institute'\n",
    "# COMPANY_NAME = 'Apple Inc.'\n",
    "\n",
    "N_NEWS = 10\n",
    "LANG = 'zh'  # {'zh', 'en'}\n",
    "SEARCH_ENGINE = 'GoogleSerper'  # {'Bing', 'Google', 'GoogleSerper'}\n",
    "LLM_PROVIDER = 'Alibaba'  # {'Alibaba', 'Baidu', 'OpenAI', 'AzureOpenAI'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670f70a1-4d87-4681-90a1-5898fec2ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LANG == 'en':\n",
    "    SEARCH_SUFFIX = 'negative news'\n",
    "    QA_TEMPLATE = '''\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use five sentences maximum and keep the answer as concise as possible.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\n",
    "'''\n",
    "    QUERY = f'''\n",
    "What is the negative news about {COMPANY_NAME}? \n",
    "Summarize no more than 3 major ones, and itemizing each one in a seperate line.\n",
    "'''\n",
    "elif LANG == 'zh':\n",
    "    SEARCH_SUFFIX = '负面新闻'\n",
    "    QA_TEMPLATE = '''\n",
    "利用下列信息回答后面的问题。如果你不知道答案就直接回答'不知道'，不要主观编造答案。\n",
    "最多使用五句话，回答尽量简洁。\n",
    "\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "有价值的回答：\n",
    "'''\n",
    "    QUERY = f'''\n",
    "{COMPANY_NAME}有哪些负面新闻？总结不超过3条主要的，每条独立一行列出。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a795b4f-7147-4679-af24-ce7780075175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "红岭创投有哪些负面新闻？总结不超过3条主要的，每条独立一行列出。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1. 红岭创投频频爆发坏账问题。\n",
      "2. 8亿坏账无法追讨，其中涉及广州纸业的1亿元至今未追回，以及部分抵押物高估（主要在地产行业）。\n",
      "3. 2015年“安徽4号标”项目出现重大兑付风险，涉及融资额度7000万元。\n"
     ]
    }
   ],
   "source": [
    "urls = fetch_urls(f'{COMPANY_NAME} {SEARCH_SUFFIX}',\n",
    "                  search_engine_wrapper=SEARCH_ENGINE, num_results=N_NEWS)\n",
    "records = fetch_web_content(urls)\n",
    "collection_name = vectorization_store(\n",
    "    records, f'{COMPANY_NAME} {SEARCH_SUFFIX}')\n",
    "qa = qa_over_docs(collection_name, QA_TEMPLATE, QUERY)\n",
    "\n",
    "print('-' * 80)\n",
    "print(qa['query'])\n",
    "print('-' * 80)\n",
    "print(qa['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085a521-ea6a-4790-8ac3-5b635de11e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
